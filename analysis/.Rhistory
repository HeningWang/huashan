rt <- rep(NA, len)
for (i in 1:len){
rt[i] <- as.numeric(unlist(rt_as_lists[i]))
}
rt <- as.data.frame(rt)
data <- cbind(data[,1:3], rt, data[,5:8])
mean(data$rt)
plot(data$rt)
max(data$rt)
filter(data,rt>100000)
exclude <- append(exclude,c("6241fc4a4e8ee","6242bd7514401","6242197550443",
"624b22243fd06","6242cc346032c","6242173eeab01",
"6242d1a5bc481","624b10a84ecda","624d710db494a"))
# ...after subsetting filler items
# exclude more than 5 none fits in experimental items
xtabs(~data$slider_value==-1, data = data)
xtabs(~none_fits + id, data = data)
exclude <- append(exclude,
c("624da2cd1ef0b","624d94a33c1bb","624d6af77ae58","624da2cd1ef0b","624b303d6bbb7",
"6242d2a1afd92","6242d016c0e11","6242d0cc141b3","6242cc346032c","6242c9a5256b1",
"6242c6ebdcebd","6242197550443","6242140018a74","6241eec9bf12f","62408e90eaa0f",
"6241fe6a604b4","6241f580649f8"))
# exclude pps und subset data
data_exclude <- subset(data, id %in% exclude)
round(xtabs(~id+list, data = data_exclude)/81) # list for second fill up
round(xtabs(~list, data = data_exclude)/81) # list for second fill up
data <- subset(data, !(id %in% exclude))
# subset NA from data
data <- subset(data, !is.na(data$slider_value))
#export current data for none fit analysis
data_preprocessed_for_analysis_of_none_fit_huashan <- data
save(data_preprocessed_for_analysis_of_none_fit_huashan, file="data_preprocessed_for_analysis_of_none_fit_huashan.Rdata")
View(data_preprocessed_for_analysis_of_none_fit_huashan)
library(tidyr)
library(ggplot2)
library(gridExtra)
library(trimr)
library(stringr)
library(lme4)
library(lmerTest)
library(dplyr)
library(effects)
library(optimx)
rm(list=ls())
plots_dir<- file.path(getwd(),"plots")
if(!dir.exists(plots_dir)) dir.create(plots_dir, recursive = TRUE, showWarnings = FALSE)
setwd("~/GitHub/huashan/analysis")
data <- read.csv(file = "../data/huashan.csv")
subj_info <-read.csv(file = "../data/huashan_subj_info.csv")
#do stuff with subj_info here:
#...
#show how many pps
sum(xtabs(~id,data=data)/180)
# show lists
xtabs(~id+list, data=data)
round(xtabs(~list, data=data)/180)
#show conditions
xtabs(~id+conditions, data=data)
# show distribution for randomized left and right per trials
xtabs(~id+leftright_trial, data=data) #TODO: check the following extrem values: 6,5,4,3,2,1, because of missing slider values
sum_left <- sum(xtabs(~leftright_trial=="1left", data=data)[2])
sum_right <- sum(xtabs(~leftright_trial=="1right", data=data)[2])
z <- c(sum_left,sum_right)
labels <- c("left","right")
piepercent<- round(100*z/sum(z), 1)
pie(z, labels=piepercent, main="Distribution of left and right", col = rainbow(length(z)))
legend("topright", c("left","right"), cex = 0.8, fill = rainbow(length(z)))
# set up levels and factors
data$conditions <- droplevels(as.factor(data$conditions))
data$id <- droplevels(as.factor(data$id))
data$slider_value <- as.numeric(data$slider_value)
data$dist <- ifelse(data$list<4, "sharp", "blurred")
#coercion slider value when missing list to NA
missing_list <- which(is.na(data$list)==TRUE)
data[missing_list,]$slider_value <- NA
#check none fit and add it to df
data$none_fits <- ifelse(data$slider_value==-1 | is.na(data$list), 1, 0)
xtabs(~item+conditions+none_fits, data)
#coercion slider value when none fit to NA
data$slider_value <- ifelse(data$slider_value==-1, NA, data$slider_value)
#exclude pps with missing list more than than 5:
xtabs(~id, data=data[is.na(data$list),])>5
exclude <- c("6242d7b615bf4", "6242d82c12542", "6242e450b3b5c", "624d80a5bdbf2")
#exclude pps with more than three s.e. away from mean experiment time
hist(subj_info$time_in_minutes)
mean(subj_info$time_in_minutes)
sd(subj_info$time_in_minutes)
x <- mean(subj_info$time_in_minutes) + 3 * sd(subj_info$time_in_minutes)
y <- mean(subj_info$time_in_minutes) - 3 * sd(subj_info$time_in_minutes)
filter(subj_info, time_in_minutes < y | time_in_minutes > x)
exclude <- append(exclude,c("6242bd7514401",
"624da2cd1ef0b",
"624b22243fd06"))
# exclude pps with more than 5 false responses to control items
# item 34-38 condition ferdc, fercf, ferdf, fzrcf, fzrdc, fzrdf
# b.t.w item 38 condition fzrcf should be none fit
filter(data, item %in% c(34,35,36,37,38) & conditions %in% c("ferdc","fercf","ferdf","fzrdc","fzrdf")
& none_fits == 1)
filter(data, item %in% c(38) & conditions %in% c("fzrcf")
& none_fits==0)
exclude <- append(exclude,c("624b303d6bbb7","6242d016c0e11","624b0affa1dad","624b0b35b7990","62420e37579a8"))
# exclude pps with extrem lang reading times
##split rt list
rt_as_lists <- with(data, strsplit(gsub("\\[|\\]", "", read_time), ","))
unlist(rt_as_lists)
len <- nrow(data)
rt <- rep(NA, len)
for (i in 1:len){
rt[i] <- as.numeric(unlist(rt_as_lists[i]))
}
rt <- as.data.frame(rt)
View(data)
library(tidyr)
library(ggplot2)
library(gridExtra)
library(trimr)
library(stringr)
library(lme4)
library(lmerTest)
library(dplyr)
library(effects)
library(optimx)
rm(list=ls())
plots_dir<- file.path(getwd(),"plots")
if(!dir.exists(plots_dir)) dir.create(plots_dir, recursive = TRUE, showWarnings = FALSE)
setwd("~/GitHub/huashan/analysis")
data <- read.csv(file = "../data/huashan.csv")
subj_info <-read.csv(file = "../data/huashan_subj_info.csv")
#do stuff with subj_info here:
#...
#show how many pps
sum(xtabs(~id,data=data)/180)
# show lists
xtabs(~id+list, data=data)
round(xtabs(~list, data=data)/180)
#show conditions
xtabs(~id+conditions, data=data)
# show distribution for randomized left and right per trials
xtabs(~id+leftright_trial, data=data) #TODO: check the following extrem values: 6,5,4,3,2,1, because of missing slider values
sum_left <- sum(xtabs(~leftright_trial=="1left", data=data)[2])
sum_right <- sum(xtabs(~leftright_trial=="1right", data=data)[2])
z <- c(sum_left,sum_right)
labels <- c("left","right")
piepercent<- round(100*z/sum(z), 1)
pie(z, labels=piepercent, main="Distribution of left and right", col = rainbow(length(z)))
legend("topright", c("left","right"), cex = 0.8, fill = rainbow(length(z)))
# set up levels and factors
data$conditions <- droplevels(as.factor(data$conditions))
data$id <- droplevels(as.factor(data$id))
data$slider_value <- as.numeric(data$slider_value)
data$dist <- ifelse(data$list<4, "sharp", "blurred")
#coercion slider value when missing list to NA
missing_list <- which(is.na(data$list)==TRUE)
data[missing_list,]$slider_value <- NA
#check none fit and add it to df
data$none_fits <- ifelse(data$slider_value==-1 | is.na(data$list), 1, 0)
xtabs(~item+conditions+none_fits, data)
#coercion slider value when none fit to NA
data$slider_value <- ifelse(data$slider_value==-1, NA, data$slider_value)
#exclude pps with missing list more than than 5:
xtabs(~id, data=data[is.na(data$list),])>5
exclude <- c("6242d7b615bf4", "6242d82c12542", "6242e450b3b5c", "624d80a5bdbf2")
#exclude pps with more than three s.e. away from mean experiment time
hist(subj_info$time_in_minutes)
mean(subj_info$time_in_minutes)
sd(subj_info$time_in_minutes)
x <- mean(subj_info$time_in_minutes) + 3 * sd(subj_info$time_in_minutes)
y <- mean(subj_info$time_in_minutes) - 3 * sd(subj_info$time_in_minutes)
filter(subj_info, time_in_minutes < y | time_in_minutes > x)
exclude <- append(exclude,c("6242bd7514401",
"624da2cd1ef0b",
"624b22243fd06"))
# exclude pps with more than 5 false responses to control items
# item 34-38 condition ferdc, fercf, ferdf, fzrcf, fzrdc, fzrdf
# b.t.w item 38 condition fzrcf should be none fit
filter(data, item %in% c(34,35,36,37,38) & conditions %in% c("ferdc","fercf","ferdf","fzrdc","fzrdf")
& none_fits == 1)
filter(data, item %in% c(38) & conditions %in% c("fzrcf")
& none_fits==0)
exclude <- append(exclude,c("624b303d6bbb7","6242d016c0e11","624b0affa1dad","624b0b35b7990","62420e37579a8"))
# exclude pps with extrem lang reading times
##split rt list
rt_as_lists <- with(data, strsplit(gsub("\\[|\\]", "", read_time), ","))
unlist(rt_as_lists)
len <- nrow(data)
rt <- rep(NA, len)
for (i in 1:len){
rt[i] <- as.numeric(unlist(rt_as_lists[i]))
}
rt <- as.data.frame(rt)
data <- cbind(data[,1:3], rt, data[,5:10])
mean(data$rt)
plot(data$rt)
max(data$rt)
filter(data,rt>100000)
exclude <- append(exclude,c("6241fc4a4e8ee","6242bd7514401","6242197550443",
"624b22243fd06","6242cc346032c","6242173eeab01",
"6242d1a5bc481","624b10a84ecda","624d710db494a"))
# ...after subsetting filler items
# exclude more than 5 none fits in experimental items
xtabs(~data$slider_value==-1, data = data)
xtabs(~none_fits + id, data = data)
exclude <- append(exclude,
c("624da2cd1ef0b","624d94a33c1bb","624d6af77ae58","624da2cd1ef0b","624b303d6bbb7",
"6242d2a1afd92","6242d016c0e11","6242d0cc141b3","6242cc346032c","6242c9a5256b1",
"6242c6ebdcebd","6242197550443","6242140018a74","6241eec9bf12f","62408e90eaa0f",
"6241fe6a604b4","6241f580649f8"))
# exclude pps und subset data
data_exclude <- subset(data, id %in% exclude)
round(xtabs(~id+list, data = data_exclude)/81) # list for second fill up
round(xtabs(~list, data = data_exclude)/81) # list for second fill up
data <- subset(data, !(id %in% exclude))
# subset NA from data
data <- subset(data, !is.na(data$slider_value))
#export current data for none fit analysis
data_preprocessed_for_analysis_of_none_fit_huashan <- data
save(data_preprocessed_for_analysis_of_none_fit_huashan, file="data_preprocessed_for_analysis_of_none_fit_huashan.Rdata")
rm(list = ls())
load ("data_preprocessed_for_analysis_of_none_fit_huashan.RData")
library(tidyr)
library(ggplot2)
library(gridExtra)
library(trimr)
library(stringr)
library(lme4)
library(lmerTest)
library(dplyr)
library(effects)
library(optimx)
# analyse none fits using glmer
#nonefit_m0 <- glmer(none_fits ~ conditions*dist + (1|id) + (1|item), data=data_preprocessed_for_analysis_of_none_fit_huashan,
#family=binomial, glmerControl(optimizer ='bobyqa'))
#mm <- allFit(nonefit_m0)
#nonefit_m1 <- update(nonefit_m0, .~.-(1|item))
nonefit_m2 <- glm(none_fits ~ conditions*dist, data = data_preprocessed_for_analysis_of_none_fit_huashan, family = binomial)
summary(nonefit_m2)
nonefit_mh0 <- glm(none_fits~none_fits, data = data_preprocessed_for_analysis_of_none_fit_huashan, family = binomial)
anova(nonefit_mh0,nonefit_m2)
# analyse none fits using glmer
nonefit_m0 <- glmer(none_fits ~ conditions*dist + (1|id) + (1|item), data=data_preprocessed_for_analysis_of_none_fit_huashan,
family=binomial, glmerControl(optimizer ='bobyqa'))
# analyse none fits using glmer
nonefit_m0 <- glmer(none_fits ~ conditions*dist + (1|id) + (1|item), data=data_preprocessed_for_analysis_of_none_fit_huashan,
family=binomial, glmerControl(optimizer ='bobyqa'))
View(data_preprocessed_for_analysis_of_none_fit_huashan)
library(tidyr)
library(ggplot2)
library(gridExtra)
library(trimr)
library(stringr)
library(lme4)
library(lmerTest)
library(dplyr)
library(effects)
library(optimx)
rm(list=ls())
plots_dir<- file.path(getwd(),"plots")
if(!dir.exists(plots_dir)) dir.create(plots_dir, recursive = TRUE, showWarnings = FALSE)
setwd("~/GitHub/huashan/analysis")
data <- read.csv(file = "../data/huashan.csv")
subj_info <-read.csv(file = "../data/huashan_subj_info.csv")
#do stuff with subj_info here:
#...
#show how many pps
sum(xtabs(~id,data=data)/180)
# show lists
xtabs(~id+list, data=data)
round(xtabs(~list, data=data)/180)
#show conditions
xtabs(~id+conditions, data=data)
# show distribution for randomized left and right per trials
xtabs(~id+leftright_trial, data=data) #TODO: check the following extrem values: 6,5,4,3,2,1, because of missing slider values
sum_left <- sum(xtabs(~leftright_trial=="1left", data=data)[2])
sum_right <- sum(xtabs(~leftright_trial=="1right", data=data)[2])
z <- c(sum_left,sum_right)
labels <- c("left","right")
piepercent<- round(100*z/sum(z), 1)
pie(z, labels=piepercent, main="Distribution of left and right", col = rainbow(length(z)))
legend("topright", c("left","right"), cex = 0.8, fill = rainbow(length(z)))
# set up levels and factors
data$conditions <- droplevels(as.factor(data$conditions))
data$id <- droplevels(as.factor(data$id))
data$slider_value <- as.numeric(data$slider_value)
data$dist <- ifelse(data$list<4, "sharp", "blurred")
#coercion slider value when missing list to NA
missing_list <- which(is.na(data$list)==TRUE)
data[missing_list,]$slider_value <- NA
#check none fit and add it to df
data$none_fits <- ifelse(data$slider_value==-1 | is.na(data$list), 1, 0)
xtabs(~item+conditions+none_fits, data)
data$slider_value <- ifelse(data$slider_value==-1, NA, data$slider_value)
exclude <- c("6242d7b615bf4", "6242d82c12542", "6242e450b3b5c", "624d80a5bdbf2")
exclude <- append(exclude,c("6242bd7514401",
"624da2cd1ef0b",
"624b22243fd06"))
exclude <- append(exclude,c("624b303d6bbb7","6242d016c0e11","624b0affa1dad","624b0b35b7990","62420e37579a8"))
exclude <- append(exclude,c("6241fc4a4e8ee","6242bd7514401","6242197550443",
"624b22243fd06","6242cc346032c","6242173eeab01",
"6242d1a5bc481","624b10a84ecda","624d710db494a"))
exclude <- append(exclude,
c("624da2cd1ef0b","624d94a33c1bb","624d6af77ae58","624da2cd1ef0b","624b303d6bbb7",
"6242d2a1afd92","6242d016c0e11","6242d0cc141b3","6242cc346032c","6242c9a5256b1",
"6242c6ebdcebd","6242197550443","6242140018a74","6241eec9bf12f","62408e90eaa0f",
"6241fe6a604b4","6241f580649f8"))
data <- subset(data, !(id %in% exclude))
#export current data for none fit analysis
data_preprocessed_for_analysis_of_none_fit_huashan <- data
save(data_preprocessed_for_analysis_of_none_fit_huashan, file="data_preprocessed_for_analysis_of_none_fit_huashan.Rdata")
#export current data for none fit analysis
data_preprocessed_for_analysis_of_none_fit_huashan <- subset(data, !is.na(data$list))
rm(list = ls())
load ("data_preprocessed_for_analysis_of_none_fit_huashan.RData")
rm(list = ls())
load ("data_preprocessed_for_analysis_of_none_fit_huashan.RData")
which(is.na(data_preprocessed_for_analysis_of_none_fit_huashan$dist)==TRUE)
missing_dist <- which(is.na(data_preprocessed_for_analysis_of_none_fit_huashan$dist)==TRUE)
data_preprocessed_for_analysis_of_none_fit_huashan[missing_dist,]
library(tidyr)
library(ggplot2)
library(gridExtra)
library(trimr)
library(stringr)
library(lme4)
library(lmerTest)
library(dplyr)
library(effects)
library(optimx)
rm(list=ls())
plots_dir<- file.path(getwd(),"plots")
if(!dir.exists(plots_dir)) dir.create(plots_dir, recursive = TRUE, showWarnings = FALSE)
setwd("~/GitHub/huashan/analysis")
data <- read.csv(file = "../data/huashan.csv")
subj_info <-read.csv(file = "../data/huashan_subj_info.csv")
#do stuff with subj_info here:
#...
#show how many pps
sum(xtabs(~id,data=data)/180)
# show lists
xtabs(~id+list, data=data)
round(xtabs(~list, data=data)/180)
#show conditions
xtabs(~id+conditions, data=data)
# show distribution for randomized left and right per trials
xtabs(~id+leftright_trial, data=data) #TODO: check the following extrem values: 6,5,4,3,2,1, because of missing slider values
sum_left <- sum(xtabs(~leftright_trial=="1left", data=data)[2])
sum_right <- sum(xtabs(~leftright_trial=="1right", data=data)[2])
z <- c(sum_left,sum_right)
labels <- c("left","right")
piepercent<- round(100*z/sum(z), 1)
pie(z, labels=piepercent, main="Distribution of left and right", col = rainbow(length(z)))
legend("topright", c("left","right"), cex = 0.8, fill = rainbow(length(z)))
# set up levels and factors
data$conditions <- droplevels(as.factor(data$conditions))
data$id <- droplevels(as.factor(data$id))
data$slider_value <- as.numeric(data$slider_value)
data$dist <- ifelse(data$list<4, "sharp", "blurred")
#coercion slider value when missing list to NA
missing_list <- which(is.na(data$list)==TRUE)
data[missing_list,]$slider_value <- NA
#check none fit and add it to df
data$none_fits <- ifelse(data$slider_value==-1 | is.na(data$list), 1, 0)
xtabs(~item+conditions+none_fits, data)
#coercion slider value when none fit to NA
data$slider_value <- ifelse(data$slider_value==-1, NA, data$slider_value)
#exclude pps with missing list more than than 5:
xtabs(~id, data=data[is.na(data$list),])>5
exclude <- c("6242d7b615bf4", "6242d82c12542", "6242e450b3b5c", "624d80a5bdbf2")
#exclude pps with more than three s.e. away from mean experiment time
hist(subj_info$time_in_minutes)
mean(subj_info$time_in_minutes)
sd(subj_info$time_in_minutes)
x <- mean(subj_info$time_in_minutes) + 3 * sd(subj_info$time_in_minutes)
y <- mean(subj_info$time_in_minutes) - 3 * sd(subj_info$time_in_minutes)
filter(subj_info, time_in_minutes < y | time_in_minutes > x)
exclude <- append(exclude,c("6242bd7514401",
"624da2cd1ef0b",
"624b22243fd06"))
# exclude pps with more than 5 false responses to control items
# item 34-38 condition ferdc, fercf, ferdf, fzrcf, fzrdc, fzrdf
# b.t.w item 38 condition fzrcf should be none fit
filter(data, item %in% c(34,35,36,37,38) & conditions %in% c("ferdc","fercf","ferdf","fzrdc","fzrdf")
& none_fits == 1)
filter(data, item %in% c(38) & conditions %in% c("fzrcf")
& none_fits==0)
exclude <- append(exclude,c("624b303d6bbb7","6242d016c0e11","624b0affa1dad","624b0b35b7990","62420e37579a8"))
# exclude pps with extrem lang reading times
##split rt list
rt_as_lists <- with(data, strsplit(gsub("\\[|\\]", "", read_time), ","))
unlist(rt_as_lists)
len <- nrow(data)
rt <- rep(NA, len)
for (i in 1:len){
rt[i] <- as.numeric(unlist(rt_as_lists[i]))
}
rt <- as.data.frame(rt)
data <- cbind(data[,1:3], rt, data[,5:10])
mean(data$rt)
plot(data$rt)
max(data$rt)
filter(data,rt>100000)
exclude <- append(exclude,c("6241fc4a4e8ee","6242bd7514401","6242197550443",
"624b22243fd06","6242cc346032c","6242173eeab01",
"6242d1a5bc481","624b10a84ecda","624d710db494a"))
# ...after subsetting filler items
# exclude more than 5 none fits in experimental items
xtabs(~data$slider_value==-1, data = data)
xtabs(~none_fits + id, data = data)
exclude <- append(exclude,
c("624da2cd1ef0b","624d94a33c1bb","624d6af77ae58","624da2cd1ef0b","624b303d6bbb7",
"6242d2a1afd92","6242d016c0e11","6242d0cc141b3","6242cc346032c","6242c9a5256b1",
"6242c6ebdcebd","6242197550443","6242140018a74","6241eec9bf12f","62408e90eaa0f",
"6241fe6a604b4","6241f580649f8"))
# exclude pps und subset data
data_exclude <- subset(data, id %in% exclude)
round(xtabs(~id+list, data = data_exclude)/81) # list for second fill up
round(xtabs(~list, data = data_exclude)/81) # list for second fill up
data <- subset(data, !(id %in% exclude))
#export current data for none fit analysis
data_preprocessed_for_analysis_of_none_fit_huashan <- subset(data, !is.na(data$list))
save(data_preprocessed_for_analysis_of_none_fit_huashan, file="data_preprocessed_for_analysis_of_none_fit_huashan.Rdata")
rm(list = ls())
load ("data_preprocessed_for_analysis_of_none_fit_huashan.RData")
library(tidyr)
library(ggplot2)
library(gridExtra)
library(trimr)
library(stringr)
library(lme4)
library(lmerTest)
library(dplyr)
library(effects)
library(optimx)
# analyse none fits using glmer
nonefit_m0 <- glmer(none_fits ~ conditions*dist + (1|id) + (1|item), data=data_preprocessed_for_analysis_of_none_fit_huashan,
family=binomial, glmerControl(optimizer ='bobyqa'))
#mm <- allFit(nonefit_m0)
#nonefit_m1 <- update(nonefit_m0, .~.-(1|item))
nonefit_m2 <- glm(none_fits ~ conditions*dist, data = data_preprocessed_for_analysis_of_none_fit_huashan, family = binomial)
summary(nonefit_m2)
nonefit_mh0 <- glm(none_fits~none_fits, data = data_preprocessed_for_analysis_of_none_fit_huashan, family = binomial)
summary(nonefit_mh0)
anova(nonefit_mh0,nonefit_m2)
missing_dist <- which(is.na(data_preprocessed_for_analysis_of_none_fit_huashan$dist)==TRUE)
data_preprocessed_for_analysis_of_none_fit_huashan[missing_dist,]
#plot(allEffects(nonefit_m1))
rm(list = ls())
load ("data_preprocessed_for_analysis_of_none_fit_huashan.RData")
library(tidyr)
library(ggplot2)
library(gridExtra)
library(trimr)
library(stringr)
library(lme4)
library(lmerTest)
library(dplyr)
library(effects)
library(optimx)
rm(list = ls())
load ("data_preprocessed_for_analysis_of_none_fit_huashan.RData")
library(tidyr)
library(ggplot2)
library(gridExtra)
library(trimr)
library(stringr)
library(lme4)
library(lmerTest)
library(dplyr)
library(effects)
library(optimx)
# analyse none fits using glmer
nonefit_m0 <- glmer(none_fits ~ conditions*dist + (1|id) + (1|item), data=data_preprocessed_for_analysis_of_none_fit_huashan,
family=binomial, glmerControl(optimizer ='bobyqa'))
# analyse none fits using glmer
nonefit_m0 <- glmer(none_fits ~ conditions*dist + (1|id) + (1|item), data=data_preprocessed_for_analysis_of_none_fit_huashan,
family=binomial, glmerControl(optimizer ='bobyqa'), REML=TRUE)
# analyse none fits using glmer
nonefit_m0 <- glmer(none_fits ~ conditions*dist + (1|id) + (1|item), data=data_preprocessed_for_analysis_of_none_fit_huashan,
family=binomial, REML=TRUE, glmerControl(optimizer ='bobyqa'))
?glmer
# analyse none fits using glmer
nonefit_m0 <- glmer(none_fits ~ conditions*dist + (1|id) + (1|item), data=data_preprocessed_for_analysis_of_none_fit_huashan,
family=binomial, nAGQ=0, control = glmerControl(optimizer ='bobyqa'))
summary(nonefit_m0)
nonefit_m1 <- glmer(none_fits ~ (1|id) + (1|item), data=data_preprocessed_for_analysis_of_none_fit_huashan,
family=binomial, nAGQ=0, control = glmerControl(optimizer ='bobyqa'))
summary(nonefit_m1)
anova(nonefit_m0,nonefit_m1)
summary(nonefit_m0)
nonefit_m1 <- glmer(none_fits ~ 1 + (1|id) + (1|item), data=data_preprocessed_for_analysis_of_none_fit_huashan,
family=binomial, nAGQ=0, control = glmerControl(optimizer ='bobyqa'))
summary(nonefit_m1)
summary(nonefit_m0)
anova(nonefit_m0,nonefit_m1)
# analyse none fits using glmer
nonefit_mh1 <- glmer(none_fits ~ 1 + conditions*dist + (1|id) + (1|item), data=data_preprocessed_for_analysis_of_none_fit_huashan,
family=binomial, nAGQ=0, control = glmerControl(optimizer ='bobyqa'))
nonefit_mh0 <- glmer(none_fits ~ 1 + (1|id) + (1|item), data=data_preprocessed_for_analysis_of_none_fit_huashan,
family=binomial, nAGQ=0, control = glmerControl(optimizer ='bobyqa'))
anova(nonefit_mh0,nonefit_mh1)
summary(nonefit_m2)
nonefit_m2 <- glm(none_fits ~ conditions*dist, data = data_preprocessed_for_analysis_of_none_fit_huashan, family = binomial)
summary(nonefit_m2)
anova(nonefit_mh1,nonefit_m2)
summary(nonefit_mh1)
nonefit_mh1$coefficient
nonefit_mh1
# analyse none fits using glmer
nonefit_mh1 <- glmer(none_fits ~ 1 + conditions*dist + (1|id) + (1|item), data=data_preprocessed_for_analysis_of_none_fit_huashan,
family=binomial, nAGQ=1, control = glmerControl(optimizer ='bobyqa'))
summary(nonefit_mh1)
anova(nonefit_mh0,nonefit_mh1)
anova(nonefit_mh1,nonefit_m2)
